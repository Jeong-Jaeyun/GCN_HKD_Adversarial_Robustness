# Project Structure Summary

Complete overview of the GCN-HKD Adversarial Robustness system architecture.

```
GCN_HKD_Adversarial_Robustness/
â”‚
â”œâ”€â”€ ðŸ“ config/                              # Configuration Management
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                           # [CORE] Hyperparameter management (dataclass-based)
â”‚   â””â”€â”€ paths.py                            # [CORE] Path management for datasets, models, logs
â”‚
â”œâ”€â”€ ðŸ“ data/                                # Data Loading & Preprocessing
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ loaders.py                          # [CORE] Dataset loaders (SARD, BigVul, D-Sieve)
â”‚   â”œâ”€â”€ preprocessors.py                    # [CORE] CFG/DFG graph construction
â”‚   â””â”€â”€ datasets.py                         # [CORE] PyTorch Dataset classes
â”‚
â”œâ”€â”€ ðŸ“ models/                              # Deep Learning Models
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                             # [CORE] Base model class
â”‚   â”œâ”€â”€ gat.py                              # [CORE] Graph Attention Network (Phase 2)
â”‚   â”œâ”€â”€ teacher.py                          # [CORE] Teacher model (clean code)
â”‚   â””â”€â”€ student.py                          # [CORE] Student model (perturbed code)
â”‚
â”œâ”€â”€ ðŸ“ adversarial/                         # Phase 1: Adversarial Transformations
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ transformations.py                  # [CORE] Code transformations (variable renaming, dead code, CFG flattening)
â”‚   â””â”€â”€ perturbations.py                    # [CORE] Graph-level attacks (node/edge perturbations)
â”‚
â”œâ”€â”€ ðŸ“ distillation/                        # Phase 3: Knowledge Distillation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ hkd.py                              # [CORE] Hierarchical knowledge distillation orchestrator
â”‚   â””â”€â”€ losses.py                           # [CORE] Distillation losses (task + KD + robustness)
â”‚
â”œâ”€â”€ ðŸ“ training/                            # Training Orchestration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ trainer.py                          # [CORE] Main training loop with KD
â”‚   â”œâ”€â”€ validator.py                        # [CORE] Validation utilities
â”‚   â””â”€â”€ callbacks.py                        # [CORE] Checkpointing, logging callbacks
â”‚
â”œâ”€â”€ ðŸ“ evaluation/                          # Robustness Evaluation
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ metrics.py                          # [CORE] Comprehensive metrics (Acc, P, R, F1, AUC-ROC, AUC-PR)
â”‚   â””â”€â”€ robustness.py                       # [CORE] Adversarial robustness evaluation
â”‚
â”œâ”€â”€ ðŸ“ utils/                               # Utility Functions
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ logger.py                           # Logging setup
â”‚   â”œâ”€â”€ graph_utils.py                      # Graph conversion and normalization
â”‚   â””â”€â”€ visualization.py                    # Plotting utilities (robustness curves, training history)
â”‚
â”œâ”€â”€ ðŸ“„ main.py                              # [ENTRY POINT] Main pipeline orchestrator
â”œâ”€â”€ ðŸ“„ example_usage.py                     # Usage examples and demonstrations
â”œâ”€â”€ ðŸ“„ requirements.txt                     # Python dependencies
â”œâ”€â”€ ðŸ“„ config_example.yaml                  # Example configuration file
â”œâ”€â”€ ðŸ“„ README.md                            # Project overview and quick start
â”œâ”€â”€ ðŸ“„ USAGE_GUIDE.md                       # Comprehensive usage guide
â”œâ”€â”€ ðŸ“„ .gitignore                           # Git ignore patterns
â””â”€â”€ ðŸ“„ PROJECT_STRUCTURE.md                 # This file

```

---

## Module Relationships

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       MAIN.PY (Entry Point)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚
        â–¼                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Config â”‚        â”‚ PathCfg  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Phase 0: Data Loading   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ - DataLoader (SARD, etc)  â”‚
    â”‚ - GraphConstructor        â”‚
    â”‚ - VulnerabilityDataset    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Phase 1: Transformations     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ - AdversarialTransformer       â”‚
    â”‚ - Code mutations (adversarial) â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Phase 2: Feature Extract  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ - GAT (Graph Attention)   â”‚
    â”‚ - TeacherModel            â”‚
    â”‚ - StudentModel            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Phase 3: Knowledge Distillation  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ - HierarchicalKD                  â”‚
    â”‚ - DistillationLoss                â”‚
    â”‚ - Feature-level + Logit-level KD  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Training                    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ - Trainer (main training loop)â”‚
    â”‚ - Callbacks (checkpointing)   â”‚
    â”‚ - Validation                  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Evaluation                   â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ - RobustnessEvaluator        â”‚
    â”‚ - MetricsComputer            â”‚
    â”‚ - Adversarial attacks        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Data Flow

```
Raw Code (Source/Binary)
        â”‚
        â–¼
Graph Construction (CFG + DFG)
        â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”
    â”‚       â”‚
    â–¼       â–¼
 Clean   Adversarial
  Code   Transform
    â”‚       â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜
        â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ Graphs â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
        â”‚
    â”Œâ”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚               â”‚
    â–¼               â–¼
  Teacher        Student
  Model          Model
    â”‚               â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
     Knowledge
    Distillation
        â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Trained      â”‚
    â”‚ Student      â”‚
    â”‚ Model        â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Evaluation      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ - Clean accuracy   â”‚
    â”‚ - Robustness       â”‚
    â”‚ - Metrics          â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Components

### 1. Configuration System (config/)
- **Purpose**: Centralized hyperparameter management
- **Files**: 
  - `config.py`: Dataclass-based configuration with all model/training/data parameters
  - `paths.py`: Automatic path creation for datasets, models, logs
- **Usage**: 
  ```python
  from config.config import Config
  config = Config()
  config = Config.from_yaml('my_config.yaml')
  ```

### 2. Data Processing (data/)
- **Purpose**: Load and preprocess vulnerability datasets
- **Files**:
  - `loaders.py`: Loaders for SARD, BigVul, D-Sieve
  - `preprocessors.py`: CFG and DFG construction from code
  - `datasets.py`: PyTorch Dataset wrappers
- **Output**: Graph-based representations of code (node features + edge indices)

### 3. Models (models/)
- **Purpose**: Neural network architectures for vulnerability detection
- **Files**:
  - `gat.py`: Graph Attention Network (recommended over standard GCN)
  - `teacher.py`: Larger model trained on clean code
  - `student.py`: Smaller model trained via knowledge distillation
- **Key Advantage**: Attention mechanism ignores adversarial noise

### 4. Adversarial Transformations (adversarial/)
- **Purpose**: Phase 1 - Create code variations that preserve semantics
- **Techniques**:
  - Variable renaming
  - Dead code insertion
  - Control flow flattening
- **Effect**: Changes graph structure without changing vulnerability status

### 5. Knowledge Distillation (distillation/)
- **Purpose**: Phase 3 - Transfer knowledge from teacher to student
- **Loss Components**:
  - Task loss (cross-entropy)
  - Logit-level KD loss (soft targets)
  - Feature-level KD loss (intermediate representations)
- **Result**: Student learns semantic features despite graph noise

### 6. Training (training/)
- **Purpose**: Orchestrate training loop with knowledge distillation
- **Components**:
  - Trainer: Main loop with forward/backward passes
  - Validator: Validation on held-out set
  - Callbacks: Checkpointing, early stopping, logging

### 7. Evaluation (evaluation/)
- **Purpose**: Comprehensive robustness and metrics evaluation
- **Metrics**:
  - Standard: Accuracy, Precision, Recall, F1
  - Advanced: AUC-ROC, AUC-PR, Matthews Correlation Coefficient
  - Robustness: Performance across perturbation budgets
- **Attacks**: Node feature, edge, and structural perturbations

### 8. Utilities (utils/)
- **Purpose**: Helper functions for logging, visualization, graph processing
- **Tools**:
  - Logger: Structured logging to file and console
  - GraphUtils: NetworkX to tensor conversion
  - Visualization: Robustness curves, training history, confusion matrices

---

## Execution Flow

### Standard Training
```python
python main.py
```

Flow:
1. Load config
2. Load datasets (SARD, BigVul, etc.)
3. Construct graphs (CFG+DFG)
4. Initialize teacher and student models
5. Training loop (with KD):
   - Forward pass on teacher (no grad)
   - Forward pass on student (with grad)
   - Compute distillation loss
   - Backward and optimize student
6. Evaluate robustness on test set
7. Save results and checkpoints

### Custom Execution
```python
# Full control over pipeline
from config.config import Config
from data.datasets import VulnerabilityDataset
from models.teacher import TeacherModel
from models.student import StudentModel
from training.trainer import Trainer

config = Config()
train_dataset = VulnerabilityDataset('SARD', split='train')
teacher = TeacherModel(input_dim=768, ...)
student = StudentModel(input_dim=768, ...)
trainer = Trainer(config, teacher, student)

for epoch in range(config.training.num_epochs):
    trainer.train_epoch(train_loader, val_loader)
```

---

## File Dependencies

```
main.py
  â”œâ”€ config/config.py
  â”œâ”€ data/loaders.py
  â”œâ”€ data/preprocessors.py
  â”œâ”€ data/datasets.py
  â”œâ”€ models/teacher.py
  â”‚   â””â”€ models/gat.py
  â”œâ”€ models/student.py
  â”‚   â””â”€ models/gat.py
  â”œâ”€ training/trainer.py
  â”‚   â”œâ”€ training/validator.py
  â”‚   â”œâ”€ distillation/hkd.py
  â”‚   â”‚   â””â”€ distillation/losses.py
  â”‚   â””â”€ training/callbacks.py
  â”œâ”€ evaluation/robustness.py
  â”‚   â”œâ”€ evaluation/metrics.py
  â”‚   â””â”€ adversarial/perturbations.py
  â””â”€ utils/logger.py
```

---

## Dataset Format Requirements

### SARD
```
data/raw/SARD/
â”œâ”€â”€ metadata.json (CWE info)
â”œâ”€â”€ labels.csv (file, cwe_id, is_vulnerable)
â””â”€â”€ source_code/ (C/C++ files)
```

### BigVul
```
data/raw/BigVul/
â”œâ”€â”€ commits.json (CVE metadata)
â”œâ”€â”€ labels.csv (commit_hash, cve_id, is_vulnerable)
â””â”€â”€ source/ (C/C++ files)
```

### D-Sieve
```
data/raw/D-Sieve/
â”œâ”€â”€ source/ (original C/C++)
â”œâ”€â”€ binaries/ (O0, O1, O2, O3)
â”œâ”€â”€ obfuscated/ (obfuscated binaries)
â””â”€â”€ labels.csv
```

---

## Configuration Hierarchy

```
Default Config (in code)
        â†“
Config File (YAML)
        â†“
Command Line Arguments
        â†“
Final Configuration
```

Priority: Command line > YAML > Default

---

## Important Classes

### Core Models
- `TeacherModel`: Larger model for clean code (teacher role)
- `StudentModel`: Smaller model for perturbed code (student role)
- `GraphAttentionNetwork`: GAT feature extractor (Phase 2)

### Data Classes
- `VulnerabilityDataset`: Single-dataset PyTorch dataset
- `MultiDatasetVulnerabilityDataset`: Multi-dataset support

### Training Classes
- `Trainer`: Main training loop with KD
- `HierarchicalKnowledgeDistillation`: KD orchestrator

### Evaluation Classes
- `RobustnessEvaluator`: Adversarial robustness testing
- `MetricsComputer`: Metric computation

### Adversarial Classes
- `AdversarialTransformer`: Code transformations
- `AdversarialAttackGenerator`: Graph perturbations

---

## Testing & Validation

Run example usage:
```bash
python example_usage.py
```

This demonstrates:
- Phase 1: Code transformations
- Phase 2: Model initialization
- Phase 3: Knowledge distillation
- Robustness evaluation

---

## Publication Checklist for Q1 Journals

âœ… Three phases clearly separated
âœ… Multiple datasets (SARD, BigVul, D-Sieve)
âœ… Real-world validation (Linux Kernel, OpenSSL)
âœ… Comprehensive metrics (accuracy, precision, recall, F1, AUC-ROC, AUC-PR)
âœ… Adversarial robustness evaluation
âœ… Comparison with baselines (GCN, CNN-based)
âœ… Ablation studies
âœ… Code and data reproducibility
âœ… Detailed architecture documentation
âœ… Professional code structure and documentation

---

## Future Extension Points

1. **Binary Analysis Module**: Add Ghidra/IDA API support
2. **LLVM Passes**: Better CFG extraction
3. **Additional Baselines**: GraphSAGE, GIN comparisons
4. **Certified Robustness**: Randomized smoothing
5. **Attention Visualization**: Interpretability tools
6. **Real-time Detection**: Server deployment

---

For detailed usage, see [USAGE_GUIDE.md](USAGE_GUIDE.md)
For quick start, see [README.md](README.md)
